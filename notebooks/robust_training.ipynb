{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e82209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------\n",
    "# SETTINGS\n",
    "# -------------------------\n",
    "ADV_EPSILON = 0.1\n",
    "ADV_EPOCHS = 5\n",
    "SAVE_PATH = \"cifake_resnet18_adv_trained.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------\n",
    "# PATHS\n",
    "# -------------------------\n",
    "TRAIN_DIR = \"/content/cifake_data/train\"\n",
    "TEST_DIR = \"/content/cifake_data/test\"\n",
    "\n",
    "# -------------------------\n",
    "# DATA TRANSFORMATIONS\n",
    "# -------------------------\n",
    "stats = ((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "\n",
    "def simulate_jpeg_compression(image_pil, quality=10):\n",
    "    buffer = io.BytesIO()\n",
    "    image_pil.save(buffer, \"JPEG\", quality=quality)\n",
    "    buffer.seek(0)\n",
    "    return Image.open(buffer)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: simulate_jpeg_compression(x, quality=30)),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# DATA LOADERS\n",
    "# -------------------------\n",
    "train_set = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform)\n",
    "test_set = datasets.ImageFolder(root=TEST_DIR, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# -------------------------\n",
    "# LOAD BASE MODEL (Phase 1 weights)\n",
    "# -------------------------\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model.load_state_dict(torch.load(\"cifake_resnet18_latest.pth\", map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "print(\"Loaded base model for adversarial training\")\n",
    "\n",
    "# -------------------------\n",
    "# FGSM FUNCTION\n",
    "# -------------------------\n",
    "def fgsm_attack(image, epsilon, grad):\n",
    "    sign_grad = grad.sign()\n",
    "    adv_image = image + epsilon * sign_grad\n",
    "    return torch.clamp(adv_image, image.min(), image.max())\n",
    "\n",
    "# -------------------------\n",
    "# ADVERSARIAL TRAIN LOOP\n",
    "# -------------------------\n",
    "def adversarial_train_epoch(model, loader, epsilon):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Adv Training\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        # ---------- STEP 1: create adversarial images ----------\n",
    "        imgs.requires_grad = True\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        adv_imgs = fgsm_attack(imgs, epsilon, imgs.grad.data)\n",
    "\n",
    "        # ---------- STEP 2: combine clean + adv ----------\n",
    "        combined_imgs = torch.cat([imgs.detach(), adv_imgs.detach()])\n",
    "        combined_labels = torch.cat([labels, labels])\n",
    "\n",
    "        # ---------- STEP 3: train on combined batch ----------\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(combined_imgs)\n",
    "        adv_loss = criterion(preds, combined_labels)\n",
    "\n",
    "        adv_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += adv_loss.item()\n",
    "\n",
    "        _, predicted = preds.max(1)\n",
    "        total += combined_labels.size(0)\n",
    "        correct += predicted.eq(combined_labels).sum().item()\n",
    "\n",
    "    return running_loss/len(loader), 100*correct/total\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# EVALUATION FUNCTION\n",
    "# -------------------------\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            _, preds = outputs.max(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "\n",
    "    return 100*correct/total\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# MAIN TRAINING LOOP\n",
    "# -------------------------\n",
    "print(\"\\nStarting Adversarial Training...\\n\")\n",
    "\n",
    "for epoch in range(ADV_EPOCHS):\n",
    "    loss, train_acc = adversarial_train_epoch(model, train_loader, ADV_EPSILON)\n",
    "    val_acc = evaluate(model, test_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{ADV_EPOCHS}] | Loss: {loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# -------------------------\n",
    "# SAVE ROBUST MODEL\n",
    "# -------------------------\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "print(f\"\\n✅ Adversarially trained model saved → {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# PHASE 3 TESTING — ROBUSTNESS CHECK\n",
    "# =========================================\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_PATH = \"cifake_resnet18_adv_trained.pth\"   # your new robust model\n",
    "EPSILON = 0.1\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LOAD ROBUST MODEL\n",
    "# -------------------------\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Robust model loaded ✅\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# FGSM ATTACK\n",
    "# -------------------------\n",
    "def fgsm_attack(image, epsilon, grad):\n",
    "    sign_grad = grad.sign()\n",
    "    adv_image = image + epsilon * sign_grad\n",
    "    return torch.clamp(adv_image, image.min(), image.max())\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CLEAN ACCURACY\n",
    "# -------------------------\n",
    "def clean_accuracy(model, loader):\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            preds = outputs.argmax(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# ADVERSARIAL ACCURACY\n",
    "# -------------------------\n",
    "def adversarial_accuracy(model, loader, epsilon):\n",
    "    correct, total = 0, 0\n",
    "    flipped = 0\n",
    "    fake_count = 0\n",
    "\n",
    "    for imgs, labels in tqdm(loader, desc=\"Testing Attack\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        imgs.requires_grad = True\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        adv_imgs = fgsm_attack(imgs, epsilon, imgs.grad.data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            adv_out = model(adv_imgs)\n",
    "            preds = adv_out.argmax(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "            fakes = (labels == 0)\n",
    "            fake_count += fakes.sum().item()\n",
    "            flipped += ((preds == 1) & fakes).sum().item()\n",
    "\n",
    "    adv_acc = 100 * correct / total\n",
    "    evasion_rate = 100 * flipped / fake_count\n",
    "\n",
    "    return adv_acc, evasion_rate\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# RUN TESTS\n",
    "# =========================================\n",
    "\n",
    "clean_acc = clean_accuracy(model, test_loader)\n",
    "adv_acc, evasion = adversarial_accuracy(model, test_loader, EPSILON)\n",
    "\n",
    "print(\"\\n========= PHASE 3 RESULTS =========\")\n",
    "print(f\"Clean Accuracy: {clean_acc:.2f}%\")\n",
    "print(f\"Adversarial Accuracy (FGSM ε={EPSILON}): {adv_acc:.2f}%\")\n",
    "print(f\"Evasion Rate (Fake → Real): {evasion:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
